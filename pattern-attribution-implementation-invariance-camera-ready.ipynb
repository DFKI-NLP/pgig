{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dabff031",
   "metadata": {},
   "source": [
    "# Arguments Against the Implementation Invariance of PA and PGIG\n",
    "\n",
    "In our [paper](https://arxiv.org/abs/2007.10685) we left the question of whether or not PGIG is implementation invariant to future work.\n",
    "\n",
    "In this notebook we present arguments against the implementation invariance of PA and PGIG. \n",
    "\n",
    "## Counter Example: Sketch\n",
    "\n",
    "The proof (by counter example) goes as follows. We construct two functionally equivalent networks which share weights in their first layers but still have different positive regimes, due to different biases. Since the $a_{+}$ pattern used for PatternAttribution in [the original paper](https://arxiv.org/abs/1705.05598) is a function of the positive regime, different patterns emerge for the shared weights. The different patterns then lead to different attributions (explanations) for identical inputs (into the two functionally equivalent networks) and thus PA and PGIG should not be implementation invariant. \n",
    "\n",
    "We consider the two networks \n",
    "\n",
    "$f'(\\mathbf{x}) = ReLU(\\mathcal{I}_{1}ReLU(\\mathbf{w}^{T}\\mathbf{x} - 0) - b)$\n",
    "\n",
    "and \n",
    "\n",
    "$f''(\\mathbf{x}) = ReLU(\\mathbf{w}^{T}\\mathbf{x} - b)$\n",
    "\n",
    "where $\\mathcal{I}_{1}=1$ is the identity matrix. The networks are functionally equivalent for $b>0$ but subtract the non-zero bias in different layers. The networks are very similar to the ones used in the [IG paper](https://arxiv.org/abs/1703.01365), in which they are also used in the context of implementation invariance.\n",
    "\n",
    "In what follows we fix weights and biases, generate data, compute patterns, modify the weights with the patterns and propagate back modified gradients, which yield the attributions according to PA. \n",
    "\n",
    "Let us set \n",
    "\n",
    "$w=(1,2)^{T}, b=1$ and refer to the first network as the network 1 and the second as network 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ca2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import Tuple\n",
    "np.random.seed(42)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf25a62",
   "metadata": {},
   "source": [
    "## Pattern Computation\n",
    "We copy the pattern functions from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661ab03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_regime(input: np.array, output: np.array, feature_in: int, feature_out: int) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Filter the positive regime. \n",
    "    \n",
    "    Args:\n",
    "        input: Input array of shape (N, features_in).\n",
    "        output: Output array of shape (N, features_out).\n",
    "        feature_in: Input feature dimension to consider with 0 <= feature_in <= dim_in.\n",
    "        feature_out: Output feature dimension to consider with\n",
    "\n",
    "    Returns: Filtered input array of shape (N-M, 1) and corresponding output array of shape (N-M, 1),\n",
    "    where M is the number of negative outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect input and output features at positions feature_in and feature_out, respectively.\n",
    "    features_in = input[:, feature_in]\n",
    "    features_out = output[:, feature_out]\n",
    "\n",
    "    # Collect inputs and corresponding outputs where feature_out > 0\n",
    "    x_plus = []\n",
    "    y_plus = []\n",
    "\n",
    "    for idx, feature_out in enumerate(features_out):\n",
    "        if feature_out > 0:\n",
    "            x_plus.append(features_in[idx])\n",
    "            y_plus.append(features_out[idx])\n",
    "            \n",
    "    return np.array(x_plus), np.array(y_plus)\n",
    "\n",
    "def patterns(input: np.array, output: np.array, weights: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    The pattern estimation according to Eq. 7 (Kindermans et al., 2017) for the positive regime.  \n",
    "\n",
    "    Args:\n",
    "        input: Input to the model of shape (N, features_in).\n",
    "        output: ReLU activated output of the model of shape (N, features_out).\n",
    "        weights: Weights of the model of shape (features_in, features_out).\n",
    "\n",
    "\n",
    "    Returns: The pattern estimation (a+) of shape (features_in, features_out).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create three matrices E[x+ y], E[x+].\n",
    "    E_x_plus_matrix = np.zeros_like(weights, dtype=np.double) \n",
    "    E_x_plus_times_y_matrix = np.zeros_like(weights, dtype=np.double)\n",
    "\n",
    "    # Populate the matrices above.\n",
    "    dims_in, dims_out = weights.shape\n",
    "    for dim_in in range(dims_in):\n",
    "        for dim_out in range(dims_out):\n",
    "            # Collect all x,y for which ReLU(wTx) = y > 0\n",
    "            x_plus, y_plus = positive_regime(input=input,\n",
    "                                             output=output,\n",
    "                                             feature_in=dim_in,\n",
    "                                             feature_out=dim_out)\n",
    "\n",
    "            # Create the expected values, aka means.\n",
    "            E_x = np.mean(x_plus)\n",
    "            E_x_y = np.mean(x_plus * y_plus)\n",
    "\n",
    "            # Populate the matrices above.\n",
    "            E_x_plus_matrix[dim_in][dim_out] = E_x \n",
    "            E_x_plus_times_y_matrix[dim_in][dim_out] = E_x_y \n",
    "\n",
    "    E_y = np.mean(output) \n",
    "    E_y_matrix = np.full_like(weights, E_y, dtype=np.double)\n",
    "\n",
    "    # Compute the nominator and denominator according to Eq. 7.\n",
    "    nominator = E_x_plus_times_y_matrix - (E_x_plus_matrix * E_y_matrix)\n",
    "    denominator = np.matmul(weights.T, E_x_plus_times_y_matrix) - np.matmul(weights.T, (E_x_plus_matrix * E_y_matrix))\n",
    "    pattern = nominator / denominator\n",
    "\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53016222",
   "metadata": {},
   "source": [
    "## Data\n",
    "We are considering a bivariate distribution. $x1$ is sampled from a normal distribution. $x2 = x1k$, where $k$ is sampled from a Rademacher distribution.\n",
    "See [Wikipedia](https://en.wikipedia.org/wiki/Normally_distributed_and_uncorrelated_does_not_imply_independent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73681699",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5000 # number of samples to work with\n",
    "mean = 0.0\n",
    "std_dev = 0.7 # change this to change pattern differences btw network 1 and network 2. \n",
    "\n",
    "\n",
    "x1 = np.random.normal(size=size, loc=mean, scale=std_dev) # loc = 0, scale = 1 if not overwritten \n",
    "rand = np.random.choice(a=[False, True], size=size, p=[.5, .5])  # Rademacher distribution \n",
    "x2 = []\n",
    "for x, r in zip(list(x1), list(rand)):\n",
    "    if r:\n",
    "        x2.append(x)\n",
    "    else:\n",
    "        x2.append(-x)\n",
    "\n",
    "ipt = np.array([np.array([_x1, _x2]) for _x1, _x2 in zip(x1, x2)]) # original input \n",
    "\n",
    "w1 = 1.\n",
    "w2 = 2.\n",
    "wgt = np.array([[w1], [w2]]) # shared weights\n",
    "\n",
    "wgt_n1_l2 = np.array([[1.0]]) # weights of the second layer of network 1\n",
    "\n",
    "opt_n1_l1 = [np.matmul(wgt.T, i) for i in ipt] # the output of the 1st layer of network 1 (w/ zero bias)\n",
    "opt_n1_l1 = np.array(opt_n1_l1)\n",
    "\n",
    "ipt_n1_l2 = np.array([max(np.array([0]), o) for o in opt_n1_l1]) # ReLU activate the output of the 1st layer\n",
    "opt_n1_l2 = np.array([i-1 for i in ipt_n1_l2]) # substract unit bias, which yields the output of the 2nd layer\n",
    "\n",
    "opt_n2_l1 = [o - 1 for o in opt_n1_l1] # the output of the 1st layer with of network 2 (w/ unit bias)\n",
    "opt_n2_l1 = np.array(opt_n2_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009341e",
   "metadata": {},
   "source": [
    "## Patterns\n",
    "In what follows we compute patterns for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1b358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patterns of network 1 layer 1 w/ zero bias:\n",
      " [[0.20428254]\n",
      " [0.39785873]]\n",
      "Patterns of network 1 layer 2 w/ unit bias:\n",
      " [[1.]]\n",
      "Patterns of network 2 layer 1 w/ unit bias:\n",
      " [[0.26148377]\n",
      " [0.36925811]]\n"
     ]
    }
   ],
   "source": [
    "patterns_network_one_layer_one = patterns(input=ipt, output=opt_n1_l1, weights=wgt)\n",
    "patterns_network_one_layer_two = patterns(input=ipt_n1_l2, output=opt_n1_l2, weights=wgt_n1_l2)\n",
    "patterns_network_two_layer_one = patterns(input=ipt, output=opt_n2_l1, weights=wgt)\n",
    "print(f'Patterns of network 1 layer 1 w/ zero bias:\\n {patterns_network_one_layer_one}')\n",
    "print(f'Patterns of network 1 layer 2 w/ unit bias:\\n {patterns_network_one_layer_two}')\n",
    "print(f'Patterns of network 2 layer 1 w/ unit bias:\\n {patterns_network_two_layer_one}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3c872",
   "metadata": {},
   "source": [
    "## Attributions \n",
    "In what follows we will compute attributions for both networks. \n",
    "\n",
    "We will consider an input that exists in all positive regimes, namely $x = (3,3)^{T}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3321d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3.0, 3.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd927af7",
   "metadata": {},
   "source": [
    "### Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f154dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatternAttribution Network 1:\n",
      " [[1.6342603]\n",
      " [6.3657397]]\n"
     ]
    }
   ],
   "source": [
    "# forward pass \n",
    "y_n1 = np.matmul(wgt.T, x) # first layer \n",
    "assert y_n1 > 0, 'ReLU should not filter in this experiment'\n",
    "y_n1 = y_n1 - 1 # second layer \n",
    "assert y_n1 > 0, 'ReLU should not filter in this experiment'\n",
    "\n",
    "# modify weights prior to backward pass \n",
    "wgt_p_n1_l1 = wgt * patterns_network_one_layer_one\n",
    "wgt_p_n1_l2 = wgt_n1_l2 * patterns_network_one_layer_two \n",
    "\n",
    "# backward pass\n",
    "grad_n1 = y_n1 # PA starts backpropagation w/ y\n",
    "grad_n1 = wgt_p_n1_l2 * grad_n1 # 2nd relu does not filter (see assertions), multiply w/ mod. weights  \n",
    "attributions_n1 = wgt_p_n1_l1  * grad_n1 # 1st relu does not filter (see assertions), multiply w/ mod. weights\n",
    "print(f'PatternAttribution Network 1:\\n {attributions_n1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea56107",
   "metadata": {},
   "source": [
    "### Network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555b5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatternAttribution Network 2:\n",
      " [[2.09187018]\n",
      " [5.90812982]]\n"
     ]
    }
   ],
   "source": [
    "# forward pass \n",
    "y_n2 = np.matmul(wgt.T, x) - 1\n",
    "assert y_n2 > 0, 'ReLU should not filter in this experiment'\n",
    "assert y_n2 == y_n1, 'Networks should be functionally equivalent'\n",
    "\n",
    "# modify weights prior to backward pass \n",
    "wgt_p_n2_l1 = wgt * patterns_network_two_layer_one\n",
    "\n",
    "# backward pass \n",
    "grad_n2 = y_n2 # PA starts backprop with y\n",
    "attributions_n2 = wgt_p_n2_l1 * grad_n2 # relu does not filter (see assertion above), multiply w/ mod. weights\n",
    "print(f'PatternAttribution Network 2:\\n {attributions_n2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e9931",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Below, the explanations for $x$ are visualized in form of heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e3e8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOZklEQVR4nO3dX6ilVRnH8d+zz4xZ/smbFFNDoX9QUcYghBGZWJLidNGFRZIinCtFISjrJrrrSuwqOFgiZUlMWWJliTmIhX/GEv+Nmoigg2JBkXbRzJz9dDE7Ow4z56z3nLXXevdvvh/Y4Oxz5t1r4OfDc5613vdEZgoAsFgmvRcAABiO4g0AC4jiDQALiOINAAuI4g0AC2jbvD/glsmFHGc5Blw1vTfW+/pXv/Cjohzc+ssr1r3OmDxx/k6yfQz4yB9/ddRMluZaqp/tuRdvQJKmk4WpyUCxnrmmeKOJpHjDUM9cU7zRxHSJ4g0/PXNN8UYTjE3giLEJ7K1u42AT/PTMNcUbTTA2gSPGJrDH2ASOGJvA3nTC2AR+euaa4o0mOCoIRxwVhD1m3nDEzBv2OG0CR5w2gT02LOGIDUvYY2wCRz1zzc+yaGI6iaJXiYg4JSJ2RcQzEbE3Ij4x5+UDR1Sa63lkm84bTVTelf+epLsz84sRcZykd9S8OFBqDqdNirNN8UYTBytt7ETEOyV9StKVkpSZ+yXtr3JxYKBauZaGZ5uxCZqYLkXRKyKWI2LPmtfyYZc6R9LfJN0SEX+JiJsj4oQO/ySgONfzyDbFG03kJMpemSuZuWPNa+WwS22T9HFJ38/McyX9W9INzf9BgAbkeg7ZpnijiYqbOi9LejkzH5r9eZcOBR5orvKG5aBsM/NGE7XOw2bmqxHxUkR8IDOflXShpKerXBwYqOY576HZpnijiax7HvZaSbfNduNfkHRVzYsDpSrnWhqQbYo3mphW3JXPzMck7ah2QWCTauZaGpZtijeamEyy9xKA6nrmmuKNJiZLFG/46ZlrijeaoPOGIzpv2KN4wxHFG/YYm8ARYxPY27Zt2nsJQHU9c03xRhOMTeCIsQnsMTaBI8YmsEfnDUd03rBH8YYjijfsbd/OhiX89Mw1xRtN0HnDEZ037FG84YjiDXucNoEjTpvA3oTf2QRDPXNN8UYTjE3giLEJ7G3jtAkM9cw1xRtN0HnDEZ037FG84YjiDXsUbziieMMeRwXhiKOCsEfnDUd03rC3nXPeMNQz1xRvNLEUvVcA1Ncz1xRvNEHxhiOKN+xRvOGI4g17E4o3DPXMNcUbTRzHhiUM9cw1xRtN8FRBOOKpgrDHzBuOmHnDHsUbjkZdvCPig5J2Sjpj9tY+SXdm5t55LgxexrZhSa5RQ89crzuxiYhvSLpdUkh6ePYKST+NiBvW+XvLEbEnIvbszn0114sFtRRZ9Gphs7me/d03s73r1RfnvlaMW2mu55HtjTrvqyV9KDMPrH0zIm6U9JSk7x7pL2XmiqQVSbplciEPtcDYTptsKtfSW7P9xPk7yfYxrmeuN/roqaR3H+H902dfA4pMouzVCLlGFaW5nke2N+q8r5d0b0T8VdJLs/feI+m9kq6pvxy4GtmG5fUi16hgtBuWmXl3RLxf0nl668bOI5m5Ou/FwceYije5Ri2jLd6SlJlTSQ82WAuM1fyxMSJelPS6pFVJBzNzx9BrkGvUUHscMiTbnPNGE3PoUC7IzL9XvyowwJw676JsU7zRxMhOmwBVjPm0CVBF6Y782nPUs9fyES6Xkn4fEY8e5etAE0NOm9TONp03mij98XLtOep1fDIz90XEqZLuiYhnMvP+LS4RGGzI2KR2tum80cRSlL1KZB66bTczX5N0hw6dGgGaK831PLJN8UYTtW5kiIgTIuKk//23pM9KenK+qweOrOZNOkOzzdgETWyfVLuT/DRJd0SEdCi/P8nMu2tdHBiiYq6lgdmmeKOJSaUH82TmC5I+WuViwBbVyrU0PNsUbzQxtkfCAjXwOyxhr9XjXoGWeuaa4o0m6LzhiM4b9mrOBoGx6Jlrijea2M6hVBjqmWuKN5qg84YjOm/YG9PzvIFaRv08b6AGOm84ovOGPU6bwBGnTWCPc95wxDlv2NtW9xkQwCj0zDXFG01wUhCOeuaa4o0mGJvAEWMT2GPDEo7YsIQ9jgrCEUcFYa/yQ+uBUeiZa4o3mmBsAkeMTWCPDUs4YsMS9ui84YjOG/aCk94w1DPXFG80MfuN2ICVnrmmeKOJSSz1XgJQXc9cU7zRBGMTOGJsAnshxibw0zPXFG80EUHnDT89c03xRhN03nBE5w17bFjCERuWsMeGJRyxYQl7nPOGI855wx6dNxzRecMeG5ZwxIYl7HFUEI44Kgh7nDaBI06bwB4zbzhi5g17zLzhiJk37DHzhiNm3rBH5w1HdN6wV7tDiYglSXsk7cvMS6teHCjUM9cUbzQxUfVd+esk7ZV0cu0LA6V65ppBJJqIiKJX4bXOlHSJpJvnumhgA6W5Lsn20FzPvfPefdmV8/4IjMBVG31Dll0nJrEsaXnNWyuZuXLYt90k6euSTiq76nxcfcm1PT8ejTy83hcLcy0VZfsmDcg1YxO0kdOybzsU5sOL9Zsi4lJJr2XmoxHx6SprAzarMNfS+tneTK4p3mhjQMg3cL6kyyLi85KOl3RyRPw4M79S6wOAYh1zzcwbbUwPlr02kJnfzMwzM/NsSZdL+gOFG92U5nqDbG8m13TeaGNarUMBxqNjrineaKPej5f/v2Tmbkm7q18YKNUx1xRvtDGHkAPddcw1xRttULzhiOINe8y84YiZN+wVnCQBFk7HXFO80QZjEzhibAJ3matF38eDY7FISnMt1c82xRttMPOGI2besMfYBI4Ym8AexRuOKN6wx2kTOOK0Cewx84YjZt6wx9gEjhibwB7FG44o3rBH8YYjijfsrbJhCUMdc03xRht03nBE5w17nDaBI06bwN40e68AqK9jrineaIPOG47ovGGP4g1HFG/YO1j+6ExgYXTMNcUbbdB5wxGdN+yxYQlHbFjCHp03HNF5wx6dNxzRecMenTcc0XnDXa7yC4jhpzTXEr+AGIuKzhuO6Lxhj+INRxRv2GPDEo7YsIQ9Om84ovOGPW6PhyNuj4c9Om84ovOGPYo3HFG8YY8NSzhiwxL26LzhiM4b9ijecETxhr1Ku/IRcbyk+yW9TYfyuyszv13l4sBQFU+bDM02xRtN5Gq12eB/JH0mM9+IiO2SHoiI32bmg7U+AChVMdfSwGxTvNFGpY2dzExJb8z+uH32YjcUfVTcsBya7Um1TwbWs5pFr4hYjog9a17Lh18qIpYi4jFJr0m6JzMfav7vAaTiXM8j23TeaCILO5TMXJG0ssH3rEr6WEScIumOiPhwZj655UUCA5XmWqqfbYo32thf/zbizPxnRNwn6WJJFG+0N4dcS2XZZmyCJnKaRa+NRMS7Zl2JIuLtki6S9Mx8Vw8cWWmu55FtOm+0UW9X/nRJt0bEkg41Hz/LzLtqXRwYpO5pk0HZpnijjXqnTR6XdG6ViwFbVfe0yaBsU7zRROXzsMAo9Mw1xRttcHs8HHXM9aY3LCPiqnW+9uZ5xudevG+zHwEjeWBa9BqD0my/9vCvWy4LI1Sa63lkeyunTb5ztC9k5kpm7sjMHe8/+4ItfARslN7MMA5F2T71vEtargljNOAmndrWHZtExONH+5Kk06qvBr7GU5glkW1UMuKZ92mSPifpH4e9H5L+NJcVwdKQO9EaIdvYsp653qh43yXpxMx87PAvRMTueSwIplbHMc9eg2xj6zrmet3inZlXr/O1L9dfDlyNrfMm26hhzJ03UMdITpIAVXXMNcUbTXCTDhxxkw78jWxsAlTB2AT2xrdhCWzdWDcsgVrGtmEJ1MCGJezlAYo3/PTMNcUbTeQ0ei8BqK5nrineaIKHCsJRz1xTvNFEJp03/PTMNcUbTSSdNwz1zDXFG00w84YjZt6wt3qQ4g0/PXNN8UYTjE3giLEJ7LFhCUdsWMIenTcc0XnD3pQNSxjqmWuKN5qg84YjOm/Ym3LaBIZ65prijSbYsIQjNixhj2ebwBHPNoE9Zt5wxMwb9rg9Ho64PR72uD0ejrg9HvYYm8ARYxPY47QJHHHaBPbovOGIzhv22LCEIzYsYY9z3nDEOW/YO3ggey8BqK5nrifdPhnHlNVpFr02EhFnRcR9EfF0RDwVEdc1WD5wRKW5nke26bzRxHS12qUOSvpaZv45Ik6S9GhE3JOZT1f7BKBQxVxLA7NN8UYT04LOo0RmviLpldl/vx4ReyWdIYnijeZq5Voanm2KN5oo7VAiYlnS8pq3VjJz5Sjfe7akcyU9tMXlAZsypPOunW2KN5oo7VBmYT5ioNeKiBMl/VzS9Zn5r62tDticIZ137WxTvNFEzV35iNiuQ+G+LTN/Ue3CwEC1T5sMyTbFG02sVjoPGxEh6QeS9mbmjXWuCmxOrVxLw7NN8UYT09VqHcr5kq6Q9EREPDZ771uZ+ZtaHwCUqphraWC2Kd5ootadaJn5gCTutcco1LzDcmi2Kd5oouaRKmAseuaa4o0muD0ejnrmmuKNJmpu7ABj0TPXFG80UXljBxiFnrmmeKMJHgkLRzwSFvbovOGIzhv26LzhiM4b9g5w2gSGeuaa4o0mOOcNR5zzhr3KD60HRqFnrineaILOG4565joy+Z+qtohYPtpD1oFFRrbHg19APB/LG38LsJDI9khQvAFgAVG8AWABUbzng5kgXJHtkWDDEgAWEJ03ACwgijcALCCKd2URcXFEPBsRz0fEDb3XA9RArseHmXdFEbEk6TlJF0l6WdIjkr6UmU93XRiwBeR6nOi86zpP0vOZ+UJm7pd0u6SdndcEbBW5HiGKd11nSHppzZ9fnr0HLDJyPUIUbwBYQBTvuvZJOmvNn8+cvQcsMnI9QhTvuh6R9L6IOCcijpN0uaQ7O68J2CpyPUI8z7uizDwYEddI+p2kJUk/zMynOi8L2BJyPU4cFQSABcTYBAAWEMUbABYQxRsAFhDFGwAWEMUbABYQxRsAFhDFGwAW0H8BK3EUcH4Z2NkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vmin = min(np.min(attributions_n1), np.min(attributions_n2))\n",
    "vmax = max(np.max(attributions_n1), np.max(attributions_n2))\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "sns.heatmap(attributions_n1, vmin=vmin, vmax=vmax, cmap=\"Spectral\", ax=ax1)\n",
    "sns.heatmap(attributions_n2, vmin=vmin, vmax=vmax,  cmap=\"Spectral\", ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60d167",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We receive two different explanations for identical inputs into functionally equivalent networks and thus PA and PGIG are not implementation invariant."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
